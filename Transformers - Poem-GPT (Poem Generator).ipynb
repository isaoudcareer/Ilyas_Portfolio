{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T18:12:02.281367Z","iopub.status.busy":"2023-03-09T18:12:02.280887Z","iopub.status.idle":"2023-03-09T18:12:02.288226Z","shell.execute_reply":"2023-03-09T18:12:02.286619Z","shell.execute_reply.started":"2023-03-09T18:12:02.281324Z"},"trusted":true},"outputs":[],"source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":58,"metadata":{"_cell_guid":"d665ac81-e653-4b29-85db-eba1e1fb1ccd","_uuid":"e0e75d42-0fc7-4640-908d-7579b91a35c1","collapsed":false,"execution":{"iopub.execute_input":"2023-03-09T12:54:31.021553Z","iopub.status.busy":"2023-03-09T12:54:31.020809Z","iopub.status.idle":"2023-03-09T12:54:31.035329Z","shell.execute_reply":"2023-03-09T12:54:31.034273Z","shell.execute_reply.started":"2023-03-09T12:54:31.021510Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","import json\n","\n","\n","class ChatData(Dataset):\n","    def __init__(self,path:str,tokenizer):\n","        self.data = json.load(open(path,\"r\"))\n","        \n","        self.X = []\n","        for i in self.data:\n","            self.X.append(str(i[\"Values\"]))\n","        \n","        for idx, i in enumerate(self.X):\n","            try:\n","                self.X[idx] = i\n","            except:\n","                break\n","\n","        print(self.X[0][:1000])\n","        \n","        self.X_encoded = tokenizer(self.X,max_length=250,truncation=True,padding=\"max_length\", return_tensors='pt')\n","        self.input_ids = self.X_encoded.input_ids\n","        self.attention_mask = self.X_encoded.attention_mask\n","         \n","    def __len__(self):\n","        return len(self.X)\n","    def __getitem__(self,idx):\n","        return (self.input_ids[idx], self.attention_mask[idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"660edc59-2b22-4d7e-9c80-e10d820e3587","_uuid":"0d273510-28c2-4383-aa6e-6574e1837c88","collapsed":true,"execution":{"iopub.execute_input":"2023-03-09T18:16:16.312639Z","iopub.status.busy":"2023-03-09T18:16:16.312180Z","iopub.status.idle":"2023-03-09T18:16:21.835761Z","shell.execute_reply":"2023-03-09T18:16:21.833590Z","shell.execute_reply.started":"2023-03-09T18:16:16.312599Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from torch.utils.data import DataLoader\n","from torch.optim import Adam\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token = tokenizer.eos_token\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","optim = Adam(model.parameters())\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c74da52-cfa1-4581-b52d-1163ed62b027","_uuid":"d500b6e9-9020-4527-a03a-e7e5bb243418","collapsed":true,"execution":{"iopub.execute_input":"2023-03-09T12:54:33.384644Z","iopub.status.busy":"2023-03-09T12:54:33.384290Z","iopub.status.idle":"2023-03-09T12:54:34.238628Z","shell.execute_reply":"2023-03-09T12:54:34.237701Z","shell.execute_reply.started":"2023-03-09T12:54:33.384607Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["import tqdm\n","import torch\n","\n","\n","def train(chatData, model,optim):\n","    epochs = 10\n","\n","    for i in tqdm.tqdm(range(epochs)):\n","        for X,a in chatData:\n","            X, a = X.to(device), a.to(device)\n","            optim.zero_grad()\n","            loss = model(X,attention_mask=a, labels=X).loss\n","            loss.backward()\n","            optim.step()\n","        torch.save(model.state_dict(), \"model_state.pt\")\n","\n","\n","data = \"/kaggle/input/poem-json/poems_data.json\"            \n","chatData = ChatData(data,tokenizer)\n","chat_loader = DataLoader(chatData,batch_size=5)\n","\n","model.train()"]},{"cell_type":"code","execution_count":61,"metadata":{"_cell_guid":"e56772d3-ab80-448b-8532-155ba10dbb62","_uuid":"9c9099d6-8137-4379-9005-d50f9d11f359","collapsed":false,"execution":{"iopub.execute_input":"2023-03-09T12:54:34.240597Z","iopub.status.busy":"2023-03-09T12:54:34.240239Z","iopub.status.idle":"2023-03-09T12:56:06.187544Z","shell.execute_reply":"2023-03-09T12:56:06.186153Z","shell.execute_reply.started":"2023-03-09T12:54:34.240560Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [01:31<00:00,  9.19s/it]\n"]}],"source":["train(chat_loader, model,optim)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T18:25:12.916807Z","iopub.status.busy":"2023-03-09T18:25:12.912867Z","iopub.status.idle":"2023-03-09T18:25:17.962121Z","shell.execute_reply":"2023-03-09T18:25:17.960542Z","shell.execute_reply.started":"2023-03-09T18:25:12.916755Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token = tokenizer.eos_token\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","model.load_state_dict(torch.load(\"/kaggle/input/poem-pt/poem_model.pt\"))\n","torch.save(model,\"poem_model.pt\")"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"8e6da8d7-934b-42ef-a4b5-a087857968dd","_uuid":"22d6a283-11da-496c-9cb8-0c31029abdec","collapsed":false,"execution":{"iopub.execute_input":"2023-03-09T18:25:27.275699Z","iopub.status.busy":"2023-03-09T18:25:27.274732Z","iopub.status.idle":"2023-03-09T18:25:27.284836Z","shell.execute_reply":"2023-03-09T18:25:27.283603Z","shell.execute_reply.started":"2023-03-09T18:25:27.275644Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def infer(inp):\n","    inp = tokenizer(inp,return_tensors=\"pt\")\n","    X = inp[\"input_ids\"] #.to(device)\n","    a = inp[\"attention_mask\"] #.to(device)\n","    output = model.generate(X, \n","                            attention_mask=a,\n","                            max_length=100,\n","                            early_stopping=True,\n","                            num_beams=5, \n","                            no_repeat_ngram_size=1)\n","    \n","    output = tokenizer.decode(output[0])\n","    \n","    return output"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T18:28:24.264486Z","iopub.status.busy":"2023-03-09T18:28:24.264097Z","iopub.status.idle":"2023-03-09T18:28:32.425361Z","shell.execute_reply":"2023-03-09T18:28:32.424265Z","shell.execute_reply.started":"2023-03-09T18:28:24.264450Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Tear my warriors against the rage \n","   I  fear  you  are  walking  the  walks  of  dreams,  The  we  do  not  envy  each other,\n"," Nor the show of the tushes of power, nor the bayonet stabs\n",".\n"," O hope and faith! O truer than steel!\n"," For we confront peace, security, all the settled laws, to unsettle them;\n"," I am more resolute because\n"]}],"source":["output = infer(\"Tear my warriors against the rage \\n\")\n","\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cc42806-b5b1-4b68-8bc9-d295d82389a1","_uuid":"1e46b116-3df2-4b04-a48f-1b399c42836e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e73c1552-6576-4366-ac90-9d43065762a9","_uuid":"29e5ce68-b1b3-4e6d-a7ad-a46b590fe3af","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
